>>> from prepare import prepare
>>> prepare()
>>> from datasets import load_dataset
>>> ontonotes = load_dataset('conll2012_ontonotesv5')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/cs/snapless/gabis/uriber/playground/venv/lib/python3.9/site-packages/datasets/load.py", line 1759, in load_dataset
    builder_instance = load_dataset_builder(
  File "/cs/snapless/gabis/uriber/playground/venv/lib/python3.9/site-packages/datasets/load.py", line 1522, in load_dataset_builder
    builder_instance: DatasetBuilder = builder_cls(
  File "/cs/snapless/gabis/uriber/playground/venv/lib/python3.9/site-packages/datasets/builder.py", line 1396, in __init__
    super().__init__(*args, **kwargs)
  File "/cs/snapless/gabis/uriber/playground/venv/lib/python3.9/site-packages/datasets/builder.py", line 319, in __init__
    self.config, self.config_id = self._create_builder_config(
  File "/cs/snapless/gabis/uriber/playground/venv/lib/python3.9/site-packages/datasets/builder.py", line 447, in _create_builder_config
    raise ValueError(
ValueError: Config name is missing.
Please pick one among the available configs: ['english_v4', 'chinese_v4', 'arabic_v4', 'english_v12']
Example of usage:
        `load_dataset('conll2012_ontonotesv5', 'english_v4')`
>>> ontonotes = load_dataset('conll2012_ontonotesv5', 'english_v12')
Found cached dataset conll2012_ontonotesv5 (/cs/snapless/gabis/uriber/playground/hf_cache/datasets/conll2012_ontonotesv5/english_v12/1.0.0/c541e760a5983b07e403e77ccf1f10864a6ae3e3dc0b994112eff9f217198c65)
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 339.29it/s]
>>> ontonotes.keys()
dict_keys(['train', 'validation', 'test'])
>>> train_set = ontonotes['train']
>>> len(train_set)
10539
>>> doc = train_set[0]
>>> doc.keys()
dict_keys(['document_id', 'sentences'])
>>> len(doc['sentences'])
235
>>> doc['sentences'][0]
{'part_id': 0, 'words': ['What', 'kind', 'of', 'memory', '?'], 'pos_tags': [48, 25, 18, 25, 8], 'parse_tree': '(TOP(SBARQ(WHNP(WHNP (WP What)  (NN kind) )(PP (IN of) (NP (NN memory) ))) (. ?) ))', 'predicate_lemmas': [None, None, None, 'memory', None], 'predicate_framenet_ids': [None, None, None, None, None], 'word_senses': [None, None, None, 1.0, None], 'speaker': 'Speaker#1', 'named_entities': [0, 0, 0, 0, 0], 'srl_frames': [], 'coref_spans': []}
>>> sentences_with_entities = [sent for sent in doc['sentences'] if len(sent['coref_spans']) > 0]
>>> len(sentences_with_entities)
178
>>> sentences_with_entities[0]
{'part_id': 0, 'words': ['WW', 'II', 'Landmarks', 'on', 'the', 'Great', 'Earth', 'of', 'China', ':', 'Eternal', 'Memories', 'of', 'Taihang', 'Mountain'], 'pos_tags': [26, 26, 27, 18, 14, 26, 26, 18, 26, 5, 19, 27, 18, 26, 26], 'parse_tree': '(TOP(NP(NP(NP (NNP WW)  (NNP II)  (NNPS Landmarks) )(PP (IN on) (NP(NP (DT the)  (NNP Great)  (NNP Earth) )(PP (IN of) (NP (NNP China) ))))) (, :) (NP(NP (JJ Eternal)  (NNPS Memories) )(PP (IN of) (NP (NNP Taihang)  (NNP Mountain) )))))', 'predicate_lemmas': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], 'predicate_framenet_ids': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], 'word_senses': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], 'speaker': 'Speaker#1', 'named_entities': [31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32], 'srl_frames': [], 'coref_spans': [[59, 8, 8], [74, 13, 14]]}
>>> sentences_with_entities[0]['words'][8]
'China'
>>> sentences_with_corefs = [sent for sent in sentences_with_entities if len(sent['coref_spans']) > len(set([entity[0] for entity in sent['coref_spans']]))]
>>> len(sentences_with_corefs)
37
>>> sentences_with_corefs[1]
{'part_id': 1, 'words': ['Roads', 'and', 'railways', 'were', 'used', 'as', 'links', 'to', 'connect', 'all', 'of', 'North', 'China', 'into', 'a', 'solid', ',', 'widespread', 'siege', ',', 'in', 'order', 'to', 'strangle', 'the', 'Eighth', 'Route', 'Army', 'and', 'its', 'base', 'areas', 'in', 'this', 'net', '.'], 'pos_tags': [28, 12, 28, 41, 43, 18, 28, 38, 40, 14, 18, 26, 26, 18, 14, 19, 5, 19, 25, 5, 18, 25, 38, 40, 14, 26, 26, 26, 12, 32, 25, 28, 18, 14, 25, 8], 'parse_tree': '(TOP(S(NP (NNS Roads)  (CC and)  (NNS railways) )(VP (VBD were) (VP (VBN used) (PP (IN as) (NP(NP (NNS links) )(SBAR(S(VP (TO to) (VP (VB connect) (NP(NP (DT all) )(PP (IN of) (NP (NNP North)  (NNP China) )))(PP (IN into) (NP (DT a)  (JJ solid)  (, ,)  (JJ widespread)  (NN siege) )))))))) (, ,) (PP (IN in) (NP (NN order) (S(VP (TO to) (VP (VB strangle) (NP(NP (DT the) (NML (NNP Eighth)  (NNP Route) ) (NNP Army) ) (CC and) (NP (PRP$ its)  (NN base)  (NNS areas) ))(PP (IN in) (NP (DT this)  (NN net) ))))))))) (. .) ))', 'predicate_lemmas': [None, None, None, 'be', 'use', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'strangle', None, None, None, None, None, None, None, None, None, None, None, None], 'predicate_framenet_ids': [None, None, None, '03', '01', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '01', None, None, None, None, None, None, None, None, None, None, None, None], 'word_senses': [None, None, None, None, 1.0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 2.0, None, None, None, None, None, None, None, None, None, None, None, None], 'speaker': 'Speaker#1', 'named_entities': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0], 'srl_frames': [{'verb': 'were', 'frames': ['O', 'O', 'O', 'B-V', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}, {'verb': 'used', 'frames': ['B-ARG1', 'I-ARG1', 'I-ARG1', 'O', 'B-V', 'B-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'O', 'B-ARGM-PRP', 'I-ARGM-PRP', 'I-ARGM-PRP', 'I-ARGM-PRP', 'I-ARGM-PRP', 'I-ARGM-PRP', 'I-ARGM-PRP', 'I-ARGM-PRP', 'I-ARGM-PRP', 'I-ARGM-PRP', 'I-ARGM-PRP', 'I-ARGM-PRP', 'I-ARGM-PRP', 'I-ARGM-PRP', 'I-ARGM-PRP', 'O']}, {'verb': 'strangle', 'frames': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'B-ARGM-LOC', 'I-ARGM-LOC', 'I-ARGM-LOC', 'O']}], 'coref_spans': [[79, 29, 29], [79, 24, 27], [21, 33, 34], [86, 9, 12], [0, 29, 31]]}
>>> sentences_with_corefs[1]['words']
['Roads', 'and', 'railways', 'were', 'used', 'as', 'links', 'to', 'connect', 'all', 'of', 'North', 'China', 'into', 'a', 'solid', ',', 'widespread', 'siege', ',', 'in', 'order', 'to', 'strangle', 'the', 'Eighth', 'Route', 'Army', 'and', 'its', 'base', 'areas', 'in', 'this', 'net', '.']
>>> sentences_with_corefs[1]['words'][29]
'its'
>>> sentences_with_corefs[1]['words'][24:28]
['the', 'Eighth', 'Route', 'Army']
